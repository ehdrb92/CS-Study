## 메모리

cpu는 메모리에 올라와 있는 인스트럭션을 하나씩 가지고 와서 처리를 한다.
메모리에는 어떤식으로 올라가게되는 것일까? 그리고 메모리의 구조는 어떻게 구성되는가?

<br>
<br>


### 메모리의 계층

메모리의 계층은 맨 아래부터 하드디스크, 메모리(RAM), 캐시, 레지스터로 이루어져 있다.

우선 하드디스크에 있는 데이터를 메모리에 올리게 된다. 그러면 메모리에 있는 것을 cpu가 읽어가서 수행하게 된다. 캐시는 메모리에서 올라온 것 들중에서 임시로 저장을 해두는 곳을 의미한다. 그렇기 때문에 다시 한번 사용할 경우 메모리까지 내려가지 않고 캐시에서 처리를 할 수 있는 것이다. 

<br>
<br>

> 캐시

캐시는 빠른 장치와 느린 장치사이에서 병목 현상을 줄여주기 위한 공간이다. 캐시를 직접설정하는 방법은 지역성의 원리에 의해서 이루어진다.
캐시는 자주 사용되는 데이터에 대해서 만들어 져야 하고, 그게 지역성이다. 지역성은 시간지역성과 공간지역성으로 나눌 수 있다.

원하느 데이터가 캐시에 있다면 캐시히트라고 하며, 있지 않은 경우를 캐시미스라고 한다. 캐시미스가 난 경우는 메모리까지 내려가서 다시 가지고 와야하기 때문에 시간이 더 걸리게 된다.

캐시를 사용하는 곳은 웹브라우저도 있고, 데이터베이스도 있다.
웹브라우저의 경우 쿠키, 로컬 스토리지, 세션 스토리지가 캐시에 해당한다. 데이터베이스의 경우 redis가 캐시계층이다.


<br>
<br>
<br>
<br>

### 메모리 관리

운영체제가 하는 대표적인 일로는 메모리관리가 있다. 한정된 메모리를 어떻게 관리해야지 효율적으로 사용할 수 있는지에 대해서 운영체제가 결저을 하게 된다.


> 가상메모리

실제 메모리는 한정되 있다. 그렇기 때문에 여러개의 프로세스가 올라갈 수 없게 되는데, 가상메모리를 통해서 메모리 자원을 추상화하여, 사용자에게 매우 큰 메모리가 있는 것 처럼 보이게 하는 것이다. 실제로 프로세스에서 동작하는 코드는 특정코드들 뿐이다. 그렇기 때문에 모든 코드를 메모리에 올릴 필요가 없다. 그렇기 때문에 필요한 부분만 올리고, 다른 부분들은 필요할 때만 올리면된다. 이렇게 해서 하나의 프로세스가 메모리에 모두 올라와 있는 것 처럼 보이게 되고, 메모리의 크기가 매우 큰 것 처럼 느낄 수 있다.

이때 사용하는 것이 논리주소이다. 논리주소는 MMU를 통해서 물리주소로 변경되게 된다.
cpu는 논리주소를 바라보고 있기 때문에, 논리주소를 통해서 물리주소를 참조하게 된다.

논리주소와 물리주소를 맵핑해둔 것이 페이지테이블이다. 페이지테이블에는 논리주소가 어느 물리주소에 해당하는지를 담고 있다.

그렇다면 페이지 테이블은 어디에 있을까?

페이지테이블은 cpu에 둘 수 없기 때문에 메모리에 두게 된다. 그렇다면 메모리를 접근하기 위해서 페이지테이블에 접근해야하는데, 페이지테이블에 접근하기 위해서 다시 메모리에 접근하는 두번의 접근이 발생하게 된다. 그러면 비효율적이 된다. 그런점을 막기 위해서 TLB가 있다. TLB는 데이터를 저장하는 캐시메모리가 아니라 주소변환을 위한 캐시메모리이다. 

그렇기 때문에 메모리에 접근을 하게 되면, 먼저 TLB에 접근해서 해당 메모리에 대한 페이지테이블이 있는지 확인 후 있다면 페이지테이블의 논리주소와 맵핑되는 물리주소에 접근하게 된다. TLB에 없다면 일반적인 접근으로 메모리에 접근하게 된다.

<br>
<br>

> 페이지폴트

페이지 폴트란 해당하는 페이지가 없는 경우로 페이지 폴트가 발생하면, 운영체제가 해당하는 페이지를 다시 올리는 작업을 한다.


<br>
<br>

> 스레싱

스레싱은 페이지폴트의 수가 높은 것을 의미한다. 페이지 폴트가 발생하면, I/O작업을 하게 된다. 그렇게 되면 cpu이용률은 떨어지게 되고, 운영체제는 cpu가 일이 없다고 생각해서 다른 프로세스를 올리게 된다. 그러면 다시 페이지 폴트가 나고, 그러면 다시 I/O작업을 하게되는데, 이런식이 반복되면서, cpu이용률이 떨어지게 되는 악순환이 스레싱이라고 한다. 
스레싱을 막는 방법으로는 작업세트와 PFF가 있다. 작업세트는 하나의 프로세스에는 실행에 꼭 필요한 것들이 있는데, 이들의 페이지 집합 working set이라고 한다. working set을 보장해주면 페이지폴트가 발생하지 않는다.

pff는 페이지폴트의 상한값과 하한값을 두고서 상한값을 넘으면 더 많은 페이지를 할당하는 방법으로 통해서 페이지폴트를 방지한다.

<br>
<br>


> 메모리 할당

프로그램을 메모리에 할당할 때는 연속할당과 불연속 할당이 있다. 메모리에 올리는 것은 통째로 올리는 것이 아니라 일정 크기로 쪼개게 되는 이 쪼갠 것을 시작위치부터 차례대로 올리는 것을 연속할당이라 하고, 비어있는 곳 아무곳에 올리는 것을 불연속할당이라고 한다.
실제로 사용되는 것은 불연속 할당이다.

불연속할당방법으로는 페이징 기법과 세그멘테이션기법, 페이지드 세그멘테이션기법이 있다.
일정한 페이지 단위로 나누는 것을 페이징기법이라고하고, 의미단위로 쪼개는 것을 세그멘테이션기법, 둘을 적절히 섞어서 사용하는 것이 페이지드 세그멘테이션기법이라고 한다.


<br>
<br>


> 페이지 교체 알고리즘

메모리는 한정되어 있기 때문에 스와핑이 많이 발생한다. 스와핑 역시 비용이므로 최대한 스와핑이 일어나지 않도록 설계를 해야한다.
스와핑은 페이지 교체 알고리즘을 기반으로 발생하게 된다.

오프라인 알고리즘은 제일 이상적이나 비현실적인 알고리즘이다. 미래에 참조되는 페이지와 현재 페이즈를 교체하는 방법이다. 하지만 미래에 어떤 페이지를 사용할지는 모르기 때문에 불가능하다. 오프라인 알고리즘은 좋은 알고리즘의 기준이 된다. 오프라인 알고리즘에 가까워질 수록 좋은 알고리즘이라고 할 수 있다.

FIFO는 먼저들어온 것을 먼저 교체해주는 것이다. 하지만 바로 뒤에 사용하는 것이 바꾸어 질수도 있다는 단점이 있다.

LRU는 가장 오래전에 참조된 페이지를 교체하는 방법이다.

LFU는 가장 적게 참조된 페이지를 교체하는 방법이다.

LRU와 LFU는 실제로는 사용하지 않는 방법이다. 실제 사용되는 방법은 NUR알고리즘이다.
